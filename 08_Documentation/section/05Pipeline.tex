
\section{Pipeline Implementation: Modules Implemented and Mathematical Explanation}
\label{sec:Mathematical Models and Algorithms for Radar-Based Object Detection}

To reliably interpret radar sensor data for static object detection and ego-motion estimation, a modular processing pipeline was developed. 
This pipeline supports both single-radar and dual-radar configurations, in both cases the inclusion of an Inertial Measurement Unit (IMU) is needed to compensate for rotational motion of the platform. 
The modular design allows adaptation to different vehicle setups and deployment conditions.

\subsection*{Sensor Data Preprocessing}
In the preprocessing of the radar data, there are two scenarios that were implemented for this project, the single-radar setup and the dual-radar setup with IMU integration.
In both radar setups, radar data is received over UART in the form of raw frames containing point cloud information. 
Each point includes its spatial coordinates $(x, y, z)$, radial velocity $v_r$, side-point info; this information comes with signal-to-noise ratio (SNR) and noise ration (dB) values that indicate the quality of each detection and range profile data.

The raw bytes are decoded \cite{understanding_uart} and structured into frame objects, which are then passed through a Physical Transformation module. 
This step converts from the sensor frame coordinates into the vehicle local frame, accounting for radar mounting position and orientation. 
This can be consider a rigid body transformation involving rotation and translation matrices.
However is really important that this process of rigid transformation is done, as the data that we obtain from the sensor does not know where it is in the vehicle, creating a missalignment between the radar data and the vehicle frame of reference.

\subsubsection*{Dual-Radar Configuration}
In the dual-radar configuration, two front-facing sensors are mounted symmetrically on the left and right sides of the vehicle, providing overlapping fields of view. 
This arrangement expands the effective coverage and reduces blind spots, offering a broader perception range compared to a single-radar setup.  

The use of two radars requires careful calibration to avoid interference effects, such as ghost detections or false targets, and to ensure consistent alignment of their outputs.  
When properly tuned, the dual-radar configuration produces a denser and more reliable point cloud, serving as a stronger foundation for subsequent stages of the odometry pipeline.

\subsection*{Frame Aggregation}
Radar point clouds are naturally sparse, especially at longer ranges. 
To improve stability and robustness, consecutive frames are aggregated into a local submap. 
This approach increases point density, reduces the effect of random noise, and provides a richer structure for downstream tasks such as clustering and alignment. 
The aggregation is performed after IMU-based alignment, ensuring that the fused frames are geometrically consistent. 

\subsection*{Filtering and Self-Speed Estimation}
Once points are aggregated and aligned, the pipeline performs filtering in two stages:

\begin{itemize}
    \item \textbf{Coordinate and SNR Filtering:} Removes points outside valid spatial boundaries or below a configurable SNR threshold.
    \item \textbf{Velocity-based Filtering:} Applies a Doppler threshold to remove points with radial velocities below or above predefined limits. This eliminates static clutter and extreme outliers, leaving only detections within the valid motion range.
\end{itemize}

From the remaining points, the vehicle self-speed is estimated using the Doppler measurements. 
A Kalman filter is then applied to smooth fluctuations and provide a stable velocity estimate, which is reused in subsequent stages of the odometry pipeline.

\subsection*{Clustering and Outlier Rejection}
The filtered detections are organized into clusters to provide structure to the radar scene. 
A two-stage clustering strategy is employed to gradually refine the set of candidate targets:  

\begin{itemize}
    \item \textbf{Stage 1 – Permissive Clustering:} A loose grouping is applied using the DBSCAN algorithm, which is well-suited for radar point clouds since it does not require the number of clusters to be specified in advance and can naturally separate sparse detections. 
    At this stage, the parameters are set permissively, allowing loosely associated points to be grouped into preliminary clusters so that potential targets are not discarded prematurely.  
    \item \textbf{Stage 2 – Strict Clustering:} The preliminary clusters are reprocessed with stricter DBSCAN parameters, enforcing tighter geometric proximity between points. 
    This refinement step eliminates loosely connected points and isolates only the detections that are spatially consistent, resulting in compact and reliable target clusters.  
\end{itemize}

This hierarchical approach ensures that targets are first captured broadly and then refined to retain only geometrically close detections, which are more suitable for downstream odometry estimation.  
Additionally, RANSAC-based outlier rejection is performed prior to clustering, further reducing the influence of inconsistent or spurious points on the cluster formation.  

DBSCAN's ability to handle varying cluster shapes, adapt to density variations, and explicitly label noise points makes it particularly advantageous in radar applications, where detections are inherently sparse, noisy, and often non-uniformly distributed.

\subsection*{ICP Alignment and Ego-Motion Estimation}
The final stage of the pipeline estimates vehicle motion by applying the Iterative Closest Point (ICP) algorithm for frame-to-frame alignment. 
ICP iteratively minimizes the distance between corresponding points across consecutive frames, computing the rigid-body transformation that best aligns them.  

In this project, ICP was applied under two distinct configurations for analysis:  

\begin{itemize}
    \item \textbf{Global ICP:} The entire aggregated point cloud from consecutive frames is used for alignment. 
    This approach provides a direct estimate of ego-motion but is sensitive to outliers and dynamic objects present in the scene.  

    \item \textbf{Cluster-based ICP:} Instead of aligning full point clouds, ICP is applied selectively on clusters identified as static targets. 
    By focusing on geometrically consistent regions, this method looks to improve robustness against moving objects and to enhance the stability of the motion estimate.  
\end{itemize}

The outcome of ICP is a rigid transformation that represents the vehicle's ego-motion between frames, serving as the foundation for radar-based odometry.

\begin{figure*}[!htbp]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tikzpicture}
            % Block style
            \tikzstyle{block} = [rectangle, draw, text width=4.5em, text centered, minimum width=6em, minimum height=4em]

            % Upper row
            \node[block] (uart) {UART\\Data};
            \node[block, right=of uart] (decoder) {Data decoder};
            \node[block, right=of decoder] (frames) {Frame};
            \node[block, right=of frames] (transform) {Rigid-Body\\Transform};
            \node[block, right=of transform] (frame_aggr) {Frame\\Aggregator};
            \node[block, right=of frame_aggr] (coord_filter) {Filter\\$x,y,z$\\$\phi$, SNR};
            \node[block, right=of coord_filter] (ransac) {RANSAC};
            \node[block, right=of ransac] (doppler_filter) {Filter\\Zero Doppler};
            \node[block, right=of doppler_filter] (clustering) {Clustering};
            \node[block, right=of clustering] (icp) {ICP};
            \node[block, right=of icp] (ego) {Ego-motion};

            % IMU and self-speed estimator (below RANSAC)
            \node[block, below=1.5cm of decoder] (imu) {IMU\\Data};
            \node[block, below=1.5cm of ransac] (self_speed_estim) {Self-speed Estimator};
            \node[block, right=of self_speed_estim] (self_speed_kalman) {Kalman Filter};

            % Connections
            \draw[->] (uart) -- (decoder);
            \draw[->] (decoder) -- (frames);
            \draw[->] (frames) -- (transform);
            \draw[->] (transform) -- (frame_aggr);
            \draw[->] (imu.east) -| ([yshift=-1.5em]frame_aggr.south) -| (frame_aggr.south);

            \draw[->] (frame_aggr) -- (coord_filter);
            \draw[->] (coord_filter) -- (ransac);
            \draw[->] (ransac) -- (doppler_filter);
            \draw[->] (doppler_filter) -- (clustering);
            \draw[->] (clustering) -- (icp);
            \draw[->] (icp) -- (ego);

            \draw[->] (ransac.south) -- (self_speed_estim.north);
            \draw[->] (self_speed_estim) -- (self_speed_kalman);

            % Bottom brace for preprocessing
            \draw [decorate, decoration = {brace, mirror, raise=10pt}]
                (uart.south west) -- (transform.south east)
                node[pos=0.5,below=15pt,black]{Sensor Data Preprocessing};
        \end{tikzpicture}
    }
    \caption{Single Radar Pipeline}
    \label{fig:single_radar_pipeline}
\end{figure*}

\begin{figure*}[!htbp]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tikzpicture}
            % Block style
            \tikzstyle{block} = [rectangle, draw, text width=4.5em, text centered, minimum width=6em, minimum height=4em]

            % Input branches
            \node[block] (radar1) {Radar\\Front Left};
            \node[block, below=1.2cm of radar1] (radar2) {Radar\\Front Right};

            % Physical transformation
            \node[block, right=1.8cm of radar1] (transform1) {Rigid-Body\\Transform};
            \node[block, below=1.2cm of transform1] (transform2) {Rigid-Body\\Transform};

            % Merge and processing
            \node[block, right=1.8cm of transform1] (merge) {Radar Merge};
            \node[block, right=of merge] (imu) {IMU};
            \node[block, right=of imu] (frame_aggr) {Frame\\Aggregator};
            \node[block, right=of frame_aggr] (coord_filter) {Filter\\$x,y,z$\\$\phi$, SNR};
            \node[block, right=of coord_filter] (ransac) {RANSAC};
            \node[block, right=of ransac] (doppler_filter) {Filter\\Zero Doppler};
            \node[block, right=of doppler_filter] (clustering) {Clustering};
            \node[block, right=of clustering] (icp) {ICP};
            \node[block, right=of icp] (ego) {Ego-motion};

            % Self-speed estimator (below RANSAC)
            \node[block, below=1.5cm of ransac] (self_speed_estim) {Self-speed Estimator};
            \node[block, right=of self_speed_estim] (self_speed_kalman) {Kalman Filter};

            % Connections
            \draw[->] (radar1) -- (transform1);
            \draw[->] (radar2) -- (transform2);
            \draw[->] (transform1) -- (merge);
            \draw[->] (transform2) -| (merge);
            \draw[->] (merge) -- (imu);
            \draw[->] (imu) -- (frame_aggr);
            \draw[->] (frame_aggr) -- (coord_filter);
            \draw[->] (coord_filter) -- (ransac);
            \draw[->] (ransac) -- (doppler_filter);
            \draw[->] (doppler_filter) -- (clustering);
            \draw[->] (clustering) -- (icp);
            \draw[->] (icp) -- (ego);

            \draw[->] (ransac.south) -- (self_speed_estim.north);
            \draw[->] (self_speed_estim) -- (self_speed_kalman);

            % Bottom brace under radar2
            \draw [decorate, decoration = {brace, mirror, raise=8pt}] 
                ([xshift=-2em,yshift=-1em]radar2.south west) -- 
                ([xshift=2em,yshift=-1em]radar2.south east)
                node[midway, below=12pt] {Dual-Radar Inputs};
        \end{tikzpicture}
    }
    \caption{Dual Radar Pipeline}
    \label{fig:dual_radar_pipeline}
\end{figure*}



\FloatBarrier\noindent